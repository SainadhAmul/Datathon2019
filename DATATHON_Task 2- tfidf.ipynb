{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from pandas_ml import ConfusionMatrix\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"D:/DATATHON/Task_2_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>news_text</th>\n",
       "      <th>news_number</th>\n",
       "      <th>news_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US bloggers banned from entering UK</td>\n",
       "      <td>111111112</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                            news_text  news_number  \\\n",
       "0           0  US bloggers banned from entering UK    111111112   \n",
       "\n",
       "        news_type  \n",
       "0  non-propaganda  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.columns =['sentence_id','news_text','news_number','news_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>news_text</th>\n",
       "      <th>news_number</th>\n",
       "      <th>news_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US bloggers banned from entering UK</td>\n",
       "      <td>111111112</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111111112</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Two prominent US bloggers have been banned fro...</td>\n",
       "      <td>111111112</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111111112</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pamela Geller and Robert Spencer co-founded an...</td>\n",
       "      <td>111111112</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                          news_text  \\\n",
       "0            0                US bloggers banned from entering UK   \n",
       "1            1                                                NaN   \n",
       "2            2  Two prominent US bloggers have been banned fro...   \n",
       "3            3                                                NaN   \n",
       "4            4  Pamela Geller and Robert Spencer co-founded an...   \n",
       "\n",
       "   news_number       news_type  \n",
       "0    111111112  non-propaganda  \n",
       "1    111111112  non-propaganda  \n",
       "2    111111112  non-propaganda  \n",
       "3    111111112  non-propaganda  \n",
       "4    111111112      propaganda  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dataframe.set_index(['sentence_id','news_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15170, 2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>news_text</th>\n",
       "      <th>news_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th>news_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>111111112</th>\n",
       "      <td>US bloggers banned from entering UK</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>111111112</th>\n",
       "      <td>NaN</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>111111112</th>\n",
       "      <td>Two prominent US bloggers have been banned fro...</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 news_text  \\\n",
       "sentence_id news_number                                                      \n",
       "0           111111112                  US bloggers banned from entering UK   \n",
       "1           111111112                                                  NaN   \n",
       "2           111111112    Two prominent US bloggers have been banned fro...   \n",
       "\n",
       "                              news_type  \n",
       "sentence_id news_number                  \n",
       "0           111111112    non-propaganda  \n",
       "1           111111112    non-propaganda  \n",
       "2           111111112    non-propaganda  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news_text    907\n",
       "news_type      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "non-propaganda    11230\n",
       "propaganda         3940\n",
       "Name: news_type, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['news_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news_text    907\n",
       "news_type      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15170, 2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "non-propaganda    10325\n",
       "propaganda         3938\n",
       "Name: news_type, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['news_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news_text    0\n",
       "news_type    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>news_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th>news_number</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>111111112</th>\n",
       "      <td>US bloggers banned from entering UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>111111112</th>\n",
       "      <td>Two prominent US bloggers have been banned fro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 news_text\n",
       "sentence_id news_number                                                   \n",
       "0           111111112                  US bloggers banned from entering UK\n",
       "2           111111112    Two prominent US bloggers have been banned fro..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df['news_type']\n",
    "df2 = df.drop('news_type',axis=1)\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df2['news_text'],y,test_size =0.3, random_state= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfidf_vectorizer.fit(X_train)\n",
    "tfidf_train = tfidf_vectorizer.transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tfidf_test.toarray())\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.731\n",
      "0.5097872340425532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "linear_clf = PassiveAggressiveClassifier(max_iter=5,tol=1e-3,random_state=1)\n",
    "\n",
    "linear_clf.fit(tfidf_train, y_train)\n",
    "pred = linear_clf.predict(tfidf_test)\n",
    "score_pa_tfidf = metrics.accuracy_score(y_test, pred)\n",
    "score_pa_tfidf = round(score_pa_tfidf,3)\n",
    "print(\"accuracy:   %0.3f\" % score_pa_tfidf)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_pa = (2*P*R)/(P+R)\n",
    "print(F1_pa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.750\n",
      "0.25815405968077726\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(tfidf_train, y_train)\n",
    "pred = lr.predict(tfidf_test)\n",
    "score_lr_tfidf = metrics.accuracy_score(y_test, pred)\n",
    "score_lr_tfidf = round(score_lr_tfidf,3)\n",
    "print(\"accuracy:   %0.3f\" % score_lr_tfidf)\n",
    "# cm_lr_tfidf = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda'])\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_lr = (2*P*R)/(P+R)\n",
    "print(F1_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.738\n",
      "0.1290824261275272\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "\n",
    "clf.fit(tfidf_train, y_train)\n",
    "\n",
    "pred = clf.predict(tfidf_test)\n",
    "score_nb_tfidf = metrics.accuracy_score(y_test, pred)\n",
    "score_nb_tfidf = round(score_nb_tfidf,3)\n",
    "print(\"accuracy:   %0.3f\" % score_nb_tfidf)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_nb_tfidf = (2*P*R)/(P+R)\n",
    "print(F1_nb_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.743\n",
      "0.31910946196660483\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=100)\n",
    "rf.fit(tfidf_train, y_train)\n",
    "pred = rf.predict(tfidf_test)\n",
    "score_rf_tfidf = metrics.accuracy_score(y_test, pred)\n",
    "score_rf_tfidf = round(score_rf_tfidf,3)\n",
    "print(\"accuracy:   %0.3f\" % score_rf_tfidf)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_rf = (2*P*R)/(P+R)\n",
    "print(F1_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.710\n",
      "0.4274527867342239\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=100)\n",
    "dt.fit(tfidf_train, y_train)\n",
    "pred = dt.predict(tfidf_test)\n",
    "score_dt_tfidf = metrics.accuracy_score(y_test, pred)\n",
    "score_dt_tfidf = round(score_dt_tfidf,3)\n",
    "print(\"accuracy:   %0.3f\" % score_dt_tfidf)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_dt = (2*P*R)/(P+R)\n",
    "print(F1_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.729\n",
      "0.23280423280423276\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(tfidf_train, y_train)\n",
    "pred = ada.predict(tfidf_test)\n",
    "score_ada_tfidf = metrics.accuracy_score(y_test, pred)\n",
    "score_ada_tfidf = round(score_ada_tfidf,3)\n",
    "print(\"accuracy:   %0.3f\" % score_ada_tfidf)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_ada = (2*P*R)/(P+R)\n",
    "print(F1_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.729\n",
      "0.45274102079395084\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(5,5,4)) \n",
    "mlp.fit(tfidf_train, y_train)\n",
    "pred = mlp.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_mlp_tfidf1=round(score,3)\n",
    "#print(score_knn_tfidf)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_mlp = (2*P*R)/(P+R)\n",
    "print(F1_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.720\n",
      "0.06396255850234009\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(tfidf_train, y_train)\n",
    "pred = knn.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_knn_tfidf=round(score,3)\n",
    "#print(score_knn_tfidf)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_knn = (2*P*R)/(P+R)\n",
    "print(F1_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.724\n",
      "0.0033698399326032016\n"
     ]
    }
   ],
   "source": [
    "svm1 = SVC(C=1.0,gamma=0.1, kernel='rbf', random_state= 54)\n",
    "svm1.fit(tfidf_train, y_train)\n",
    "pred = svm1.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_svm_tfidf = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_svm_tf1 = (2*P*R)/(P+R)\n",
    "print(F1_svm_tf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.723\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "svm2 = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)\n",
    "svm2.fit(tfidf_train, y_train)\n",
    "pred = svm2.predict(tfidf_test)\n",
    "score1 = metrics.accuracy_score(y_test, pred)\n",
    "score_svm_tfidf2 = round(score1,3)\n",
    "print(\"accuracy:   %0.3f\" % score1)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_svm2_tf = (2*P*R)/(P+R)\n",
    "print(F1_svm2_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>DT</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Logistic</th>\n",
       "      <th>MLP_NN</th>\n",
       "      <th>NB</th>\n",
       "      <th>Passive Aggresive</th>\n",
       "      <th>RF</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model Accuracy_tfidf</th>\n",
       "      <td>0.729000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.729000</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>0.731000</td>\n",
       "      <td>0.743000</td>\n",
       "      <td>0.72400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score_tfidf</th>\n",
       "      <td>0.232804</td>\n",
       "      <td>0.427453</td>\n",
       "      <td>0.063963</td>\n",
       "      <td>0.258154</td>\n",
       "      <td>0.452741</td>\n",
       "      <td>0.129082</td>\n",
       "      <td>0.509787</td>\n",
       "      <td>0.319109</td>\n",
       "      <td>0.00337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      AdaBoost        DT       KNN  Logistic    MLP_NN  \\\n",
       "Model Accuracy_tfidf  0.729000  0.710000  0.720000  0.750000  0.729000   \n",
       "F1 Score_tfidf        0.232804  0.427453  0.063963  0.258154  0.452741   \n",
       "\n",
       "                            NB  Passive Aggresive        RF      SVM  \n",
       "Model Accuracy_tfidf  0.738000           0.731000  0.743000  0.72400  \n",
       "F1 Score_tfidf        0.129082           0.509787  0.319109  0.00337  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc2 = {'Passive Aggresive':score_pa_tfidf,'Logistic':score_lr_tfidf,'AdaBoost':score_ada_tfidf,'NB':score_nb_tfidf,\n",
    "       'RF':score_rf_tfidf,'DT':score_dt_tfidf,'KNN':score_knn_tfidf,\"MLP_NN\":score_mlp_tfidf1,\"SVM\":score_svm_tfidf}\n",
    "F1_tfidf = {'Passive Aggresive':F1_pa,'Logistic':F1_lr,'AdaBoost':F1_ada,'NB':F1_nb_tfidf,\n",
    "      'RF':F1_rf,'DT':F1_dt,'KNN':F1_knn,\"MLP_NN\":F1_mlp,\"SVM\":F1_svm_tf1}\n",
    "acc_tfidf = pd.DataFrame([acc2,F1_tfidf])\n",
    "acc_tfidf.index=['Model Accuracy_tfidf','F1 Score_tfidf']\n",
    "acc_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn,fp,fn,tp = confusion_matrix(test_dy,test_pred).ravel() \n",
    "# sensitivity = (tp/(tp+fn))*100 # recall\n",
    "# specificity = (tn/(tn+fp))*100\n",
    "# accuracy = ((tp+tn)/(tp+tn+fp+fn))*100\n",
    "\n",
    "# tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "# R = (tp/(tp+fn))*100 # recall\n",
    "# P = (tp/(tp+fp))*100 # precision\n",
    "# F1 = (2*P*R)/(P+R)\n",
    "# print(tn,fp,fn,tp,sensitivity,specificity, F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `count_vectorizer` \n",
    "count_vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit(X_train)\n",
    "count_train = count_vectorizer.transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.925\n",
      "0.6969583176868194\n"
     ]
    }
   ],
   "source": [
    "## Fitting Naive Baye's Classifier for Multinomial Model\n",
    "clf = MultinomialNB()\n",
    "clf.fit(count_train, y_train)\n",
    "pred = clf.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_nb = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_nb_cnt = (2*P*R)/(P+R)\n",
    "print(F1_nb_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.953\n",
      "0.7739052725647899\n"
     ]
    }
   ],
   "source": [
    "## Fitting Passive Aggresive Classifier Model\n",
    "\n",
    "linear_clf = PassiveAggressiveClassifier(n_iter=50)\n",
    "\n",
    "linear_clf.fit(count_train, y_train)\n",
    "pred = linear_clf.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_pa = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_pa_cnt = (2*P*R)/(P+R)\n",
    "print(F1_pa_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.914\n",
      "0.3796109993293092\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=100)\n",
    "rf.fit(count_train, y_train)\n",
    "pred = rf.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_rf = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_rf_cnt = (2*P*R)/(P+R)\n",
    "print(F1_rf_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.924\n",
      "0.6399647887323944\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=100,max_depth=2)\n",
    "dt.fit(count_train, y_train)\n",
    "pred = dt.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_dt = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_dt_cnt = (2*P*R)/(P+R)\n",
    "print(F1_dt_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.956\n",
      "0.7812354853692521\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(count_train, y_train)\n",
    "pred = lr.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_lr = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_lr_cnt = (2*P*R)/(P+R)\n",
    "print(F1_lr_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.940\n",
      "0.6796019900497512\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(count_train, y_train)\n",
    "pred = ada.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_ada = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_ada_cnt = (2*P*R)/(P+R)\n",
    "print(F1_ada_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.895\n",
      "0.5563850687622789\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(5,5,4)) # initially(554_0.787)(573_0.556)\n",
    "mlp.fit(count_train, y_train)\n",
    "pred = mlp.predict(count_test)\n",
    "score= metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_mlp=round(score,3)\n",
    "#print(score_knn_tfidf)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_mlp_cnt = (2*P*R)/(P+R)\n",
    "print(F1_mlp_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.893\n",
      "0.03494176372712146\n"
     ]
    }
   ],
   "source": [
    "svm1 = SVC()\n",
    "svm1.fit(count_train, y_train)\n",
    "pred = svm1.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_svm1 = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_svm_cnt = (2*P*R)/(P+R)\n",
    "print(F1_svm_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.898\n",
      "0.16067329762815608\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(count_train, y_train)\n",
    "pred = knn.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_knn = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_knn_cnt = (2*P*R)/(P+R)\n",
    "print(F1_knn_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>DT</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Logistic</th>\n",
       "      <th>MLP_NN</th>\n",
       "      <th>NB</th>\n",
       "      <th>Passive Aggresive</th>\n",
       "      <th>RF</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model Accuracy_cnt</th>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.924000</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.953000</td>\n",
       "      <td>0.914000</td>\n",
       "      <td>0.893000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score_cnt</th>\n",
       "      <td>0.679602</td>\n",
       "      <td>0.639965</td>\n",
       "      <td>0.160673</td>\n",
       "      <td>0.781235</td>\n",
       "      <td>0.787394</td>\n",
       "      <td>0.696958</td>\n",
       "      <td>0.773905</td>\n",
       "      <td>0.379611</td>\n",
       "      <td>0.034942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    AdaBoost        DT       KNN  Logistic    MLP_NN  \\\n",
       "Model Accuracy_cnt  0.940000  0.924000  0.898000  0.956000  0.958000   \n",
       "F1 Score_cnt        0.679602  0.639965  0.160673  0.781235  0.787394   \n",
       "\n",
       "                          NB  Passive Aggresive        RF       SVM  \n",
       "Model Accuracy_cnt  0.925000           0.953000  0.914000  0.893000  \n",
       "F1 Score_cnt        0.696958           0.773905  0.379611  0.034942  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc1 = {'Passive Aggresive':score_cnt_pa,'Logistic':score_cnt_lr,'AdaBoost':score_cnt_ada,'NB':score_cnt_nb,\n",
    "       'RF':score_cnt_rf,'DT':score_cnt_dt,'KNN':score_cnt_knn,\"MLP_NN\":score_cnt_mlp,\"SVM\":score_cnt_svm1}\n",
    "\n",
    "F1_cnt = {'Passive Aggresive':F1_pa_cnt,'Logistic':F1_lr_cnt,'AdaBoost':F1_ada_cnt,'NB':F1_nb_cnt,\n",
    "          'RF':F1_rf_cnt,'DT':F1_dt_cnt,'KNN':F1_knn_cnt,\"MLP_NN\":F1_mlp_cnt,\"SVM\":F1_svm_cnt}\n",
    "acc_cnt = pd.DataFrame([acc1,F1_cnt])\n",
    "acc_cnt.index=['Model Accuracy_cnt','F1 Score_cnt']\n",
    "acc_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>DT</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Logistic</th>\n",
       "      <th>MLP_NN</th>\n",
       "      <th>NB</th>\n",
       "      <th>Passive Aggresive</th>\n",
       "      <th>RF</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model Accuracy_cnt</th>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.924000</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.953000</td>\n",
       "      <td>0.914000</td>\n",
       "      <td>0.893000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score_cnt</th>\n",
       "      <td>0.679602</td>\n",
       "      <td>0.639965</td>\n",
       "      <td>0.160673</td>\n",
       "      <td>0.781235</td>\n",
       "      <td>0.787394</td>\n",
       "      <td>0.696958</td>\n",
       "      <td>0.773905</td>\n",
       "      <td>0.379611</td>\n",
       "      <td>0.034942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Accuracy_tfidf</th>\n",
       "      <td>0.939000</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.943000</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>0.891000</td>\n",
       "      <td>0.961000</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score_tfidf</th>\n",
       "      <td>0.678082</td>\n",
       "      <td>0.641860</td>\n",
       "      <td>0.553425</td>\n",
       "      <td>0.664488</td>\n",
       "      <td>0.787091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.804048</td>\n",
       "      <td>0.343967</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      AdaBoost        DT       KNN  Logistic    MLP_NN  \\\n",
       "Model Accuracy_cnt    0.940000  0.924000  0.898000  0.956000  0.958000   \n",
       "F1 Score_cnt          0.679602  0.639965  0.160673  0.781235  0.787394   \n",
       "Model Accuracy_tfidf  0.939000  0.922000  0.925000  0.943000  0.959000   \n",
       "F1 Score_tfidf        0.678082  0.641860  0.553425  0.664488  0.787091   \n",
       "\n",
       "                            NB  Passive Aggresive        RF       SVM  \n",
       "Model Accuracy_cnt    0.925000           0.953000  0.914000  0.893000  \n",
       "F1 Score_cnt          0.696958           0.773905  0.379611  0.034942  \n",
       "Model Accuracy_tfidf  0.891000           0.961000  0.912000  0.891000  \n",
       "F1 Score_tfidf             NaN           0.804048  0.343967       NaN  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = acc_cnt\n",
    "performance.append(acc_tfidf, ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e4777e7ff494>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:/DATATHON/output/dev-INPUT/dev-INPUT/task-1/task1.dev.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"D:/DATATHON/output/dev-INPUT/dev-INPUT/task-1/task1.dev.txt\",delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv(\"D:/DATATHON/datasets-v3/New_Task1.train.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/DATATHON/datasets-v3/New_Task1.train.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
